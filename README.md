# Claude Code Telemetry ğŸ“Š

<p align="center">
  <img src="https://img.shields.io/badge/Version-1.0.0-blue" alt="Version">
  <img src="https://img.shields.io/badge/License-MIT-green" alt="License">
  <img src="https://img.shields.io/badge/Coverage-95.44%25-brightgreen" alt="Code Coverage">
  <img src="https://img.shields.io/badge/Docker-Required-blue" alt="Docker">
  <img src="https://img.shields.io/badge/Node.js-18+-green" alt="Node.js">
</p>

<p align="center">
  <strong>See exactly how you/your team uses Claude Code</strong><br>
  Track costs, usage patterns, and session data in real-time
</p>

---

https://github.com/user-attachments/assets/2634cec3-94af-4a2d-90da-44cd641f1746


## ğŸ¯ What This Actually Does

Claude Code Telemetry is a lightweight bridge that captures telemetry data from Claude Code and forwards it to Langfuse for visualization. You get:

- ğŸ’° **Cost Tracking** - See costs per session, user, and model
- ğŸ“Š **Usage Metrics** - Token counts, cache hits, and tool usage
- â±ï¸ **Session Grouping** - Automatically groups work into 1-hour sessions
- ğŸ” **Full Transparency** - Every API call logged with complete details
- ğŸ” **Safe local data** - The packaged self-hosted Langfuse keeps your data local

The original motivation from the author was that when using Claude Code Pro/Max, it didn't have good options for telemetry out of the box compared to API-based requests that can be integrated with various solutions and wanted to provide a secure turnkey local setup for people using Claude Code to benefit from.

### ğŸ—ï¸ Built on Standards
Uses **OpenTelemetry** for data collection, **Langfuse** for visualization, and **Claude's native observability** APIs. No proprietary formats, no vendor lock-in.

## ğŸš€ Quick Start (30 seconds)

### Prerequisites
ğŸ³ **Docker Desktop** - [Install here](https://docker.com/products/docker-desktop) if you don't see the whale icon in your menu bar

### Setup
```bash
# Clone and enter directory
git clone https://github.com/lainra/claude-code-telemetry && cd claude-code-telemetry

# Run automated setup
./quickstart.sh

# Enable telemetry
source claude-telemetry.env

# Test it works
claude "What is 2+2?"
```

**That's it!** View your dashboard at http://localhost:3000

### Need Help?
Let Claude guide you through the setup:
```bash
claude "Set up the telemetry dashboard"
```

## ğŸ“¸ What You'll See in Langfuse

### Session View
Every conversation becomes a trackable session:
```
Session: 4:32 PM - 5:15 PM (43 minutes)
â”œâ”€â”€ Total Cost: $18.43
â”œâ”€â”€ API Calls: 6 (2 Haiku, 4 Opus)
â”œâ”€â”€ Total Tokens: 45,231 (31,450 cached)
â”œâ”€â”€ Tools Used:
â”‚   â”œâ”€â”€ Read: 23 calls
â”‚   â”œâ”€â”€ Edit: 8 calls
â”‚   â”œâ”€â”€ Bash: 4 calls
â”‚   â””â”€â”€ Grep: 2 calls
â””â”€â”€ Cache Savings: $12.30 (40% cost reduction)
```

### Individual API Calls
Full details for every Claude interaction:
```
4:45 PM - claude-3-opus-20240229
â”œâ”€â”€ Input: 12,453 tokens (8,234 from cache)
â”œâ”€â”€ Output: 3,221 tokens
â”œâ”€â”€ Cost: $4.87
â”œâ”€â”€ Duration: 3.2s
â””â”€â”€ Context: Feature implementation
```

### Cost Breakdown
Track spending by model and user:
```
Today's Usage:
â”œâ”€â”€ Total: $67.43
â”œâ”€â”€ By Model:
â”‚   â”œâ”€â”€ Opus: $61.20 (91%)
â”‚   â””â”€â”€ Haiku: $6.23 (9%)
â””â”€â”€ By User:
    â”œâ”€â”€ alex@team.com: $28.90
    â”œâ”€â”€ sarah@team.com: $22.15
    â””â”€â”€ mike@team.com: $16.38
```

## ğŸ”§ How It Works

```
Claude Code â†’ OpenTelemetry â†’ Telemetry Bridge â†’ Langfuse
     â†“              â†“               â†“                â†“
  User asks     Sends OTLP    Parses & forwards   Shows in
  questions    telemetry data   to Langfuse       dashboard
```

The bridge:
1. Listens for OpenTelemetry data from Claude Code
2. Enriches it with session context
3. Forwards to Langfuse for visualization
4. Groups related work into analyzable sessions

## ğŸŒŸ What This Tool Is (and Isn't)

### âœ… What It Does:
- **Tracks costs** - Know exactly what you're spending
- **Shows usage patterns** - See when and how Claude is used
- **Groups work sessions** - Understand complete tasks, not just individual calls
- **Provides full transparency** - Every token and dollar accounted for
- **Runs locally** - Your data stays on your infrastructure

### âŒ What It Doesn't Do:
- **Measure productivity** - Can't tell if you're working faster
- **Analyze code quality** - Doesn't evaluate AI-generated code
- **Provide strategic insights** - Just shows raw data, not recommendations
- **Enable team collaboration** - No sharing or pattern discovery features
- **Calculate ROI** - You'll need to determine value yourself

## ğŸ› ï¸ Installation Options

### Option 1: Full Stack (Recommended)
Includes Langfuse dashboard + telemetry bridge:
```bash
./quickstart.sh
```

### Option 2: Bridge Only (Manual w/NPM)
Already have Langfuse? Just run the bridge:
```bash
# Configure your existing Langfuse credentials
export LANGFUSE_PUBLIC_KEY=your-public-key
export LANGFUSE_SECRET_KEY=your-secret-key
export LANGFUSE_HOST=your-langfuse-url

# Install and start the bridge
npm install
npm start
```

### Option 3: Bridge Only (Docker)
Already have Langfuse? Run the bridge in Docker:
```bash
# Create .env file with your Langfuse credentials
cp .env.example .env
# Edit .env with your LANGFUSE_PUBLIC_KEY, LANGFUSE_SECRET_KEY, and LANGFUSE_HOST

# Run just the telemetry bridge container
docker compose up telemetry-bridge
```

## ğŸ“‹ Requirements

- Docker Desktop ([install](https://docker.com/products/docker-desktop)) - For quickstart
- Claude Code CLI (`claude`)
- Node.js 18+ (optional) - For bridge-only mode

## ğŸ›ï¸ Configuration

| Setting | Default | Description |
|---------|---------|-------------|
| `SESSION_TIMEOUT` | 1 hour | Groups related work into sessions |
| `OTLP_RECEIVER_PORT` | 4318 | OpenTelemetry standard port |
| `LANGFUSE_HOST` | http://localhost:3000 | Langfuse dashboard URL |
| `LOG_LEVEL` | info | Logging verbosity |

See `.env.example` for all options.

### ğŸ·ï¸ Custom Langfuse Tags, Metadata & Trace Names

You can customize how traces appear in Langfuse by setting environment variables before running Claude Code:

```bash
# Custom trace name (appears in Langfuse trace list)
export LANGFUSE_TRACE_NAME="feature-development"

# Tags for filtering and grouping in Langfuse
# Supports separators: semicolon (;), pipe (|), or comma (,)
export LANGFUSE_TRACE_TAGS="project-alpha;backend;refactoring"

# Custom metadata as JSON (appears in trace details)
export LANGFUSE_TRACE_METADATA='{"project":"alpha","sprint":12,"team":"platform"}'

# Custom user ID (overrides auto-detected user)
export LANGFUSE_USER_ID="developer@company.com"

# Custom session ID (overrides auto-generated session)
export LANGFUSE_SESSION_ID="sprint-12-auth-feature"
```

#### Example: Team Project Tracking

```bash
# Set up tracking for a specific project
export LANGFUSE_TRACE_NAME="auth-system-redesign"
export LANGFUSE_TRACE_TAGS="auth;security;q1-2025"
export LANGFUSE_TRACE_METADATA='{"jira":"AUTH-123","reviewer":"jane@company.com"}'

# Now run Claude Code - all traces will be tagged
claude "Implement OAuth2 flow"
```

#### Example: Per-Task Tracking

```bash
# Track different types of work
export LANGFUSE_TRACE_TAGS="bugfix;production;urgent"
claude "Fix the authentication timeout issue"

# Change tags for different work
export LANGFUSE_TRACE_TAGS="feature;backend;normal"
claude "Add rate limiting to API endpoints"
```

These customizations help you:
- **Filter traces** by project, team, or task type in Langfuse
- **Group related work** across multiple sessions
- **Add business context** (Jira tickets, sprint numbers, reviewers)
- **Track costs** per project or feature

### ğŸ“¤ OTLP Export to OpenTelemetry Collector

Forward telemetry data to an OpenTelemetry Collector for integration with Jaeger, Prometheus, Grafana, and other observability backends.

```bash
# Enable OTLP export
export OTLP_EXPORT_ENABLED=true
export OTLP_EXPORT_ENDPOINT=http://otel-collector:4318

# Start the telemetry bridge
npm start
```

**Environment Variables:**

| Variable | Default | Description |
|----------|---------|-------------|
| `OTLP_EXPORT_ENABLED` | `false` | Enable OTLP export |
| `OTLP_EXPORT_ENDPOINT` | - | Collector endpoint (e.g., `http://localhost:4318`) |
| `OTLP_EXPORT_METRICS_ENDPOINT` | - | Override for metrics endpoint |
| `OTLP_EXPORT_LOGS_ENDPOINT` | - | Override for logs endpoint |
| `OTLP_EXPORT_TIMEOUT` | `5000` | Request timeout in ms |
| `OTLP_EXPORT_RETRIES` | `3` | Number of retries |
| `OTLP_EXPORT_HEADERS` | - | Auth headers (e.g., `Authorization=Bearer token`) |

**Architecture with OTLP Export:**

```
Claude Code â†’ OTLP â†’ Telemetry Bridge â†’ Langfuse (dashboard)
                           â†“
                    OpenTelemetry Collector
                           â†“
                    Jaeger / Prometheus / Grafana
```

## ğŸ”’ Privacy & Security

- **100% Local** - No external services unless you configure them
- **No Code Storage** - Only metadata about interactions
- **You Control the Data** - Runs on your infrastructure
- **Optional Prompt Logging** - Choose whether to log prompts

## ğŸ“š Documentation

- [Environment Variables](docs/ENVIRONMENT_VARIABLES.md) - Complete configuration guide
- [Telemetry Guide](docs/TELEMETRY_GUIDE.md) - Understanding the data format

## ğŸ¤” Should You Use This?

**Use this if you want to:**
- Track Claude Code costs across your team
- Understand usage patterns and peak times  
- Have transparency into AI tool spending
- Keep telemetry data on your own infrastructure

## ğŸ¤ Contributing

We welcome contributions! Please see our [Contributing Guide](CONTRIBUTING.md) for details.

## ğŸ“„ License

MIT License - see [LICENSE](LICENSE) for details.

---

<p align="center">
  <strong>Simple, honest telemetry for Claude Code</strong><br>
  <em>100% AI-assisted repository, made with â¤ï¸ by Claude and <a href="https://github.com/lainra">@lainra</a></em><br><br>
  <a href="https://github.com/lainra/claude-code-telemetry/issues">Report Issue</a> Â· 
  <a href="https://github.com/lainra/claude-code-telemetry/pulls">Submit PR</a>
</p>
